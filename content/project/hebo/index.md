---
date: "2021-05-26T00:00:00Z"
external_link: ""
slides: ''
summary: Heteroscedastic Evolutionary Bayesian Optimisation.
tags:
- Deep Learning
- Hyperparameter Optimisation
- Bayesian inference
title: Bayesian Hyperparameter Optimisation
url_code: ""
url_pdf: ""
url_slides: "pdf/Slides_HEBO_pres.pdf"
url_video: ""
---

Inspired by the increasing desire to efficiently tune machine learning hyper-parameters, in this work we rigorously analyse conventional and non-conventional assumptions inherent to Bayesian optimisation. Across an extensive set of experiments we conclude that: 1) the majority of hyper-parameter tuning tasks exhibit heteroscedasticity and non-stationarity, 2) multi-objective acquisition ensembles with Pareto-front solutions significantly improve queried configurations, and 3) robust acquisition maximisation affords empirical advantages relative to its non-robust counterparts. We hope these findings may serve as guiding principles, both for practitioners and for further research in the field